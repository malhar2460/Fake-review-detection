{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries and donwloading resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\MALHAR\n",
      "[nltk_data]     PRAJAPATI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\MALHAR PRAJAPATI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\MALHAR\n",
      "[nltk_data]     PRAJAPATI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from textstat import flesch_reading_ease\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\", force=True)\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Lexical diversity \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical diversity assesses the variety of unique words in a text, indicating vocabulary richness. A higher score suggests diverse content, while a lower score implies repetition. This metric helps analyze writing styles and enhances NLP model performance.  \n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Lexical Diversity} = \\frac{\\text{Unique Words}}{\\text{Total Words}}\n",
    "$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    \"\"\"\n",
    "    Computes the lexical diversity of a given text.\n",
    "\n",
    "    Lexical diversity is the ratio of unique words to total words, indicating vocabulary richness.\n",
    "    Higher values suggest diverse writing, while lower values indicate repetition.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input text for lexical diversity calculation.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Lexical diversity score (Unique Words / Total Words). Returns 0 for empty text.\n",
    "    \"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    return len(set(words)) / len(words) if len(words) > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Computes the lexical diversity of a given text.\n",
      "\n",
      "    Lexical diversity is the ratio of unique words to total words, indicating vocabulary richness.\n",
      "    Higher values suggest diverse writing, while lower values indicate repetition.\n",
      "\n",
      "    Parameters:\n",
      "    -----------\n",
      "    text : str\n",
      "        Input text for lexical diversity calculation.\n",
      "\n",
      "    Returns:\n",
      "    --------\n",
      "    float\n",
      "        Lexical diversity score (Unique Words / Total Words). Returns 0 for empty text.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(lexical_diversity.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Example of how the doc will look like to any other person using this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuation count helps analyze writing style by measuring the frequency of punctuation marks in a text. Higher punctuation usage can indicate expressive or complex writing, while lower usage suggests simpler or more straightforward text. This feature enhances NLP models by capturing tone, structure, and readability variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_count(text):\n",
    "    \"\"\"\n",
    "    Computes the number of punctuation characters in a given text.\n",
    "\n",
    "    This function counts the occurrences of punctuation marks in the input text.\n",
    "    It helps in analyzing text structure and writing style.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input text from which punctuation characters are counted.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        Total count of punctuation characters in the text.\n",
    "    \"\"\"\n",
    "    return sum(1 for char in text if char in string.punctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Average word length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average word length helps analyze writing complexity by measuring the typical length of words in a text. Longer words indicate formal or technical writing, while shorter words suggest simplicity. This feature improves NLP models by capturing variations in writing styles.  \n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Average Word Length} = \\frac{\\sum \\text{Length of Each Word}}{\\text{Total Words}}\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(text):\n",
    "    \"\"\"\n",
    "    Computes the average word length in a given text.\n",
    "\n",
    "    This function calculates the mean length of words by dividing the total number \n",
    "    of characters in all words by the total word count. It provides insight into \n",
    "    text complexity, readability, and writing style.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input text for analysis.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        The average word length. Returns 0 if the text is empty.\n",
    "    \"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    return sum(len(word) for word in words) / len(words) if words else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### NER(Named Entity Recognition) Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named entity count identifies the number of proper nouns (e.g., names, places, organizations) in a text. It helps analyze text structure and detect formal or factual content, aiding in fake review detection and sentiment analysis.  \n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Named Entity Count} = \\text{Number of Proper Nouns Detected}\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entity_count(text):\n",
    "    \"\"\"\n",
    "    Counts the number of named entities in a given text.\n",
    "\n",
    "    This function estimates the count of named entities (e.g., proper nouns) \n",
    "    by identifying words that start with an uppercase letter followed by lowercase letters. \n",
    "    While this is a simplistic approach, it can provide a rough measure of entity presence \n",
    "    in the text.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input text for analysis.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        The number of detected named entities.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)  \n",
    "    return len(doc.ents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### POS(Part Of Speech) Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function counts words in a text that belong to a specific part-of-speech (POS) category. It helps analyze sentence structure and linguistic patterns, aiding in text classification and sentiment analysis.  \n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{POS Tag Count} = \\sum \\mathbf{1} \\quad \\text{if tag starts with specified prefix}\n",
    "$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos_tags(text, tag_prefix):\n",
    "    \"\"\"\n",
    "    Counts the number of words in a text that belong to a specified part-of-speech (POS) category.\n",
    "\n",
    "    This function tokenizes the input text, assigns POS tags using NLTK's `pos_tag` function, \n",
    "    and counts how many words have tags that start with the given prefix. POS prefixes include:\n",
    "    - \"NN\" for nouns\n",
    "    - \"VB\" for verbs\n",
    "    - \"JJ\" for adjectives\n",
    "    - \"RB\" for adverbs\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The input text to be analyzed.\n",
    "    tag_prefix : str\n",
    "        The prefix of the POS tag to count (e.g., \"NN\" for nouns, \"VB\" for verbs).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        The count of words matching the specified POS tag prefix.\n",
    "    \"\"\"\n",
    "    tokens = nltk.pos_tag(word_tokenize(text))\n",
    "    return sum(1 for _, tag in tokens if tag.startswith(tag_prefix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Sentiment Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment polarity determines the emotional tone of a text, indicating whether it is positive, negative, or neutral. This feature is useful in sentiment analysis, fake review detection, and opinion mining.  \n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Sentiment Polarity} \\in [-1, 1]\n",
    "$$  \n",
    "- 1 → Positive sentiment  \n",
    "- 0 → Neutral sentiment  \n",
    "- -1 → Negative sentiment  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_polarity(text):\n",
    "    \"\"\"\n",
    "    Computes the sentiment polarity of a given text.\n",
    "\n",
    "    Sentiment polarity measures the emotional tone of a text, \n",
    "    ranging from -1 (negative sentiment) to +1 (positive sentiment), \n",
    "    with 0 indicating a neutral sentiment. This function utilizes \n",
    "    TextBlob's sentiment analysis to evaluate the polarity.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The input text for sentiment analysis.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        A polarity score between -1 and 1, where:\n",
    "        - Negative values indicate negative sentiment.\n",
    "        - Positive values indicate positive sentiment.\n",
    "        - A value close to 0 suggests neutrality.\n",
    "    \"\"\"\n",
    "    return TextBlob(text).sentiment.polarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Subjectivity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjectivity measures the degree to which a text expresses personal opinions rather than factual statements. It is useful in sentiment analysis, fake review detection, and opinion mining.  \n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Subjectivity Score} \\in [0, 1]\n",
    "$$  \n",
    "- **1** → Highly subjective (opinion-based)  \n",
    "- **0** → Highly objective (fact-based)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_score(text):\n",
    "    \"\"\"\n",
    "    Computes the subjectivity score of a given text.\n",
    "\n",
    "    Subjectivity measures the degree of personal opinion, emotion, \n",
    "    or bias in a text. The score ranges from 0 to 1, where:\n",
    "    - 0 indicates an objective statement (fact-based content).\n",
    "    - 1 indicates a highly subjective statement (opinion-based content).\n",
    "\n",
    "    This function utilizes TextBlob's sentiment analysis to evaluate \n",
    "    the subjectivity of the text.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The input text for subjectivity analysis.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        A subjectivity score between 0 and 1, where:\n",
    "        - Scores closer to 0 suggest objective language.\n",
    "        - Scores closer to 1 suggest subjective language.\n",
    "    \"\"\"\n",
    "    return TextBlob(text).sentiment.subjectivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Flesch Reading Ease Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flesch Reading Ease score assesses the readability of a text. Higher scores indicate simpler text, while lower scores suggest more complex writing. It helps in detecting fake reviews by identifying unnatural writing patterns.\n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{FRE} = 206.835 - (1.015 \\times \\frac{\\text{Total Words}}{\\text{Total Sentences}}) - (84.6 \\times \\frac{\\text{Total Syllables}}{\\text{Total Words}})\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flesch_reading_ease_score(text):\n",
    "    \"\"\"\n",
    "    Computes the Flesch Reading Ease score for a given text.\n",
    "\n",
    "    The Flesch Reading Ease score evaluates text readability based on \n",
    "    sentence length and word complexity. The score typically ranges from 0 to 100, where:\n",
    "    \n",
    "    - 90–100: Very easy to read (understandable by 5th graders).\n",
    "    - 60–70: Standard readability (understandable by 8th-9th graders).\n",
    "    - 0–30: Very difficult to read (best suited for academic or technical texts).\n",
    "\n",
    "    A higher score indicates better readability.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The input text whose readability score is to be calculated.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        The Flesch Reading Ease score, or 0 if the input is not a valid string.\n",
    "    \"\"\"\n",
    "    return flesch_reading_ease(text) if isinstance(text, str) else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Sentence Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence length represents the total number of words in a text. It helps analyze writing style, as fake reviews may have distinct sentence structures compared to genuine ones. This metric is useful for linguistic pattern analysis.\n",
    "\n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Sentence Length} = \\text{Number of Words in a Sentence}\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_length(text):\n",
    "    \"\"\"\n",
    "    Computes the number of words in a given text.\n",
    "\n",
    "    This function tokenizes the input text and counts the number of words.\n",
    "    It helps in analyzing sentence complexity and structure, which can be\n",
    "    useful in readability assessments and linguistic studies.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The input text for which the word count is to be determined.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        The total number of words in the text.\n",
    "    \"\"\"\n",
    "    return len(word_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinig all things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for preprocessed_lemmatization...\n",
      "Features extracted & saved: ../Data/Feature-Engineered/preprocessed_lemmatization_features.csv\n",
      "Extracting features for preprocessed_no_stopwords...\n",
      "Features extracted & saved: ../Data/Feature-Engineered/preprocessed_no_stopwords_features.csv\n",
      "Extracting features for preprocessed_stemming...\n",
      "Features extracted & saved: ../Data/Feature-Engineered/preprocessed_stemming_features.csv\n",
      "Extracting features for preprocessed_stemming_no_stopwords...\n",
      "Features extracted & saved: ../Data/Feature-Engineered/preprocessed_stemming_no_stopwords_features.csv\n",
      "Extracting features for preprocessed_no_stopwords_no_lemmatization...\n",
      "Features extracted & saved: ../Data/Feature-Engineered/preprocessed_no_stopwords_no_lemmatization_features.csv\n",
      "All feature-engineered datasets saved in '../Data/Feature-Engineered/'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def feature_engineering(df, filename):\n",
    "    print(f\"Extracting features for {filename}...\")\n",
    "    # Ensure that 'processed_text' is a string and fill missing values with an empty string\n",
    "    df[\"processed_text\"] = df[\"processed_text\"].fillna(\"\").astype(str)\n",
    "    \n",
    "    # print(df['processed_text'].head())\n",
    "    \n",
    "    df[\"lexical_diversity\"] = df[\"processed_text\"].apply(lexical_diversity)\n",
    "    df[\"avg_word_length\"] = df[\"processed_text\"].apply(average_word_length)\n",
    "    df[\"sentiment_polarity\"] = df[\"processed_text\"].apply(sentiment_polarity)\n",
    "    df[\"subjectivity\"] = df[\"processed_text\"].apply(subjectivity_score)\n",
    "    df[\"flesch_reading_ease\"] = df[\"processed_text\"].apply(flesch_reading_ease_score)\n",
    "    df[\"sentence_length\"] = df[\"processed_text\"].apply(sentence_length)\n",
    "    df[\"named_entity_count\"] = df[\"processed_text\"].apply(named_entity_count)\n",
    "    df[\"punctuation_count\"] = df[\"processed_text\"].apply(punctuation_count)\n",
    "    df[\"noun_count\"] = df[\"processed_text\"].apply(lambda x: count_pos_tags(x, \"NN\"))\n",
    "    df[\"verb_count\"] = df[\"processed_text\"].apply(lambda x: count_pos_tags(x, \"VB\"))\n",
    "    df[\"adj_count\"] = df[\"processed_text\"].apply(lambda x: count_pos_tags(x, \"JJ\"))\n",
    "    df[\"adv_count\"] = df[\"processed_text\"].apply(lambda x: count_pos_tags(x, \"RB\"))\n",
    "    \n",
    "    filepath = f\"../Data/Feature-Engineered/{filename}_features.csv\"\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Features extracted & saved: {filepath}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "datasets = [\n",
    "    \"preprocessed_lemmatization\",\n",
    "    \"preprocessed_no_stopwords\",\n",
    "    \"preprocessed_stemming\",\n",
    "    \"preprocessed_stemming_no_stopwords\",\n",
    "    \"preprocessed_no_stopwords_no_lemmatization\",\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f\"../Data/Pre-processed/{dataset}.csv\")\n",
    "    feature_engineering(df, dataset)\n",
    "\n",
    "print(\"All feature-engineered datasets saved in '../Data/Feature-Engineered/'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
