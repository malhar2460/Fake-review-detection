{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"pip install -q dagshub mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted run fa710c3a46af46968df305121281663e from experiment Fake Review Detection\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/malhar.c.prajapati/my-first-repo.mlflow\")\n",
    "client = MlflowClient()\n",
    "default_experiment = client.get_experiment_by_name(\"Fake Review Detection\")\n",
    "runs = client.search_runs(experiment_ids=[default_experiment.experiment_id])\n",
    "for run in runs:\n",
    "    client.delete_run(run.info.run_id)\n",
    "    print(f\"Deleted run {run.info.run_id} from experiment {default_experiment.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 23:10:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run preprocessed_lemmatization_features.csv at: https://dagshub.com/malhar.c.prajapati/my-first-repo.mlflow/#/experiments/1/runs/3e917cd4a4634697878c7d9ea88e5601\n",
      "üß™ View experiment at: https://dagshub.com/malhar.c.prajapati/my-first-repo.mlflow/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 23:25:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run preprocessed_no_stopwords_features.csv at: https://dagshub.com/malhar.c.prajapati/my-first-repo.mlflow/#/experiments/1/runs/98b0681cda65417eb2d4165f768f3bee\n",
      "üß™ View experiment at: https://dagshub.com/malhar.c.prajapati/my-first-repo.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/malhar.c.prajapati/my-first-repo.mlflow\")\n",
    "mlflow.set_experiment(\"Fake Review Detection\")\n",
    "\n",
    "files = [\n",
    "    \"../Data/Feature-Engineered/preprocessed_lemmatization_features.csv\",\n",
    "    \"../Data/Feature-Engineered/preprocessed_no_stopwords_features.csv\",\n",
    "    \"../Data/Feature-Engineered/preprocessed_no_stopwords_no_lemmatization_features.csv\",\n",
    "    \"../Data/Feature-Engineered/preprocessed_stemming_features.csv\",\n",
    "    \"../Data/Feature-Engineered/preprocessed_stemming_no_stopwords_features.csv\"\n",
    "]\n",
    "\n",
    "embeddings = {\n",
    "    \"Tfidf\": TfidfVectorizer(max_features=5000),\n",
    "    \"Count\": CountVectorizer(max_features=5000)\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": (LogisticRegression, {\"C\": [0.01, 0.1, 1, 10], \"solver\": [\"liblinear\", \"lbfgs\"], \"max_iter\": [100, 200, 500]}),\n",
    "    \"RandomForest\": (RandomForestClassifier, {\"n_estimators\": [50, 100], \"max_depth\": [None, 10, 20]}),\n",
    "    \"SVC\": (SVC, {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]})\n",
    "}\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    df.dropna(inplace=True)\n",
    "    le = LabelEncoder()\n",
    "    df[\"label_encoded\"] = le.fit_transform(df[\"label\"])\n",
    "    text_features = df[\"processed_text\"]\n",
    "    numeric_features = df[[\"lexical_diversity\", \"avg_word_length\", \"sentiment_polarity\", \"subjectivity\", \"flesch_reading_ease\", \"sentence_length\", \"named_entity_count\", \"noun_count\", \"verb_count\", \"adj_count\", \"adv_count\"]]\n",
    "    y = df[\"label_encoded\"]\n",
    "    scaler = StandardScaler()\n",
    "    X_numeric = scaler.fit_transform(numeric_features)\n",
    "    for emb_name, vectorizer in embeddings.items():\n",
    "        X_text = vectorizer.fit_transform(text_features).toarray()\n",
    "        X = np.hstack((X_text, X_numeric)).astype(np.float32)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        for model_name, (model_class, param_grid) in models.items():\n",
    "            run_name = os.path.basename(f) + \"_\" + emb_name + \"_\" + model_name\n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                mlflow.log_param(\"file_name\", f)\n",
    "                mlflow.log_param(\"embedding\", emb_name)\n",
    "                mlflow.log_param(\"model\", model_name)\n",
    "                grid_search = GridSearchCV(model_class(), param_grid, cv=5, scoring=\"accuracy\", n_jobs=1)\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_model = grid_search.best_estimator_\n",
    "                preds = best_model.predict(X_test)\n",
    "                acc = accuracy_score(y_test, preds)\n",
    "                prec = precision_score(y_test, preds, average=\"weighted\")\n",
    "                rec = recall_score(y_test, preds, average=\"weighted\")\n",
    "                f1 = f1_score(y_test, preds, average=\"weighted\")\n",
    "                mlflow.log_params(grid_search.best_params_)\n",
    "                mlflow.log_metric(\"accuracy\", acc)\n",
    "                mlflow.log_metric(\"precision\", prec)\n",
    "                mlflow.log_metric(\"recall\", rec)\n",
    "                mlflow.log_metric(\"f1_score\", f1)\n",
    "                mlflow.sklearn.log_model(best_model, model_name + \"_Model\")\n",
    "                cm = confusion_matrix(y_test, preds)\n",
    "                plt.figure(figsize=(7, 5))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "                plt.xlabel(\"Predicted\")\n",
    "                plt.ylabel(\"Actual\")\n",
    "                cm_file = \"../Reports/confusion_matrix_\" + run_name + \".png\"\n",
    "                plt.savefig(cm_file)\n",
    "                mlflow.log_artifact(cm_file)\n",
    "                plt.close()\n",
    "                results_list.append([os.path.basename(f), emb_name, model_name, acc, prec, rec, f1])\n",
    "\n",
    "dl_results = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    df.dropna(inplace=True)\n",
    "    le = LabelEncoder()\n",
    "    df[\"label_encoded\"] = le.fit_transform(df[\"label\"])\n",
    "    text_features = df[\"processed_text\"]\n",
    "    y = df[\"label_encoded\"].values\n",
    "    num_classes = len(np.unique(y))\n",
    "    vocab_size = 10000\n",
    "    max_length = 200\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(text_features)\n",
    "    sequences = tokenizer.texts_to_sequences(text_features)\n",
    "    padded = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "    X = padded\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, 128, input_length=max_length),\n",
    "        LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1, verbose=0)\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    preds_prob = model.predict(X_test)\n",
    "    preds = preds_prob.argmax(axis=1)\n",
    "    prec = precision_score(y_test, preds, average=\"weighted\")\n",
    "    rec = recall_score(y_test, preds, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, preds, average=\"weighted\")\n",
    "    run_name = \"DL_LSTM_\" + os.path.basename(f)\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_param(\"file_name\", f)\n",
    "        mlflow.log_param(\"model\", \"LSTM\")\n",
    "        mlflow.log_param(\"embedding\", \"Tokenizer+Embedding\")\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"precision\", prec)\n",
    "        mlflow.log_metric(\"recall\", rec)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.keras.log_model(model, \"LSTM_Model\")\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        cm_file = \"../Reports/confusion_matrix_DL_\" + os.path.basename(f) + \".png\"\n",
    "        plt.savefig(cm_file)\n",
    "        mlflow.log_artifact(cm_file)\n",
    "        plt.close()\n",
    "        dl_results.append([os.path.basename(f), \"LSTM\", \"DL\", acc, prec, rec, f1])\n",
    "\n",
    "all_results = results_list + dl_results\n",
    "results_df = pd.DataFrame(all_results, columns=[\"File\", \"Embedding/ModelType\", \"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
